---
title: "TO414_Group_11_Project_4"
author: "Jack Perlmuter, Ross Coyne, Logan Sabella, Mason Wicklander, Antonio De Llergo"
date: "2/21/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Laying out the Problem
We have chosen a data set that highlights whether or not patients had strokes and other associated information. We intend to build a model that can accurately predict whether or not a patient will have a stroke based on the presence of certain dependent variables (such as gender, heart disease, bmi). The business implications of this are for physicians to be able to plug their patients' information into our model and be able to predict whether or not the patient is going to have a stroke. As a result, patients can be made aware of their potential risk of stroke and stroke deaths can be prevented.


# Importing the Data Set and Cleaning It
```{r}
stroke <- read.csv("healthcare-dataset-stroke-data.csv")

#Observing summary and structure of data to identify what we need to clean
summary(stroke)
str(stroke)

#We decided to set ID to NULL, as it is an irrelevant variable
stroke$id <- NULL

#Renamed column stroke in order to prevent confusion
stroke$had_stroke <- stroke$stroke
stroke$stroke <- NULL

#We set the following columns as factors instead of characters
stroke$gender <- as.factor(stroke$gender)
stroke$smoking_status <- as.factor(stroke$smoking_status)
stroke$ever_married <- as.factor(stroke$ever_married)
stroke$work_type <- as.factor(stroke$work_type)
stroke$Residence_type <- as.factor(stroke$Residence_type)

#We set bmi to be numeric, as it was a character to begin. Then, we removed all NAs and replaced them with the mean (difference between mean and median was negligible, so we decided to preserve the mean)
stroke$bmi <- as.numeric(stroke$bmi)
stroke$bmi <- ifelse(is.na(stroke$bmi), mean(stroke$bmi, na.rm = T),stroke$bmi)

#Observing summary and structure of the cleaned data
summary(stroke)
str(stroke)
```

# Understanding the Data / Splitting the Data into Train and Test
```{r}
table(stroke$had_stroke)
prop.table(table(stroke$had_stroke))

#We need to upsample our data because it is a 95:5 split right now and we want it closer to 50:50
library(caret)
set.seed(17)

strokeup =upSample(x = stroke[,-ncol(stroke)], y = as.factor(stroke$had_stroke))
strokeup$had_stroke = strokeup$Class
strokeup$Class = NULL




#Should be using "trainup" for train sets and "test" for test sets from now on

# Using model.matrix to convert all the factors to dummy variables
# We are converting all of the factors into dummy variables as the input into knn has to be numeric

strokeupmm <- as.data.frame(model.matrix(~.-1,strokeup))
str(strokeupmm)

#Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

strokeup_random <- strokeupmm[sample(nrow(strokeupmm)),]
# we are going to normalize everything 
strokeup_norm <- as.data.frame(lapply(strokeup_random, normalize))

```

# KNN Model
```{r}
library(class)

sqrt(nrow(strokeup_norm))

strokeup_label <- strokeup_norm[,"had_stroke1"]

knn_pred <- knn(train=strokeup_norm,test=strokeup_norm,cl=strokeup_label,k=83)
confusionMatrix(as.factor(knn_pred),as.factor(strokeup_norm$had_stroke1),positive="1")
```



# Building an ANN Model
```{r}
library(neuralnet)

# ANN model 
stroke.ann <- neuralnet(formula = had_stroke1 ~ .,
                              data = strokeup_norm, hidden = 1, stepmax = 1e+06)

# Visualize the network topology
plot(stroke.ann)

# Create a confusion matrix to see model accuracy
ann_pred <- predict(stroke.ann,strokeup_norm,type = "response")
ann_pred <- ifelse(ann_pred > 0.5, 1, 0)
confusionMatrix(as.factor(ann_pred),as.factor(strokeup_norm$had_stroke1),positive = "1")

```

# Logistic Regression Model
```{r}
logit.model <- glm(had_stroke ~ ., data = strokeup, family = "binomial")
summary(logit.model)

newlogit.model <- glm(had_stroke ~ age + hypertension + avg_glucose_level, data = strokeup, family = "binomial")
summary(newlogit.model)

logit_pred <- predict(logit.model,strokeup,type="response")
logit_pred <- ifelse(logit_pred>0.5,1,0)
confusionMatrix(as.factor(logit_pred),strokeup$had_stroke,positive="1")
```

=======
# SVM
```{r}
library(kernlab)

stroke.svm = ksvm(had_stroke ~., data = strokeup, kernel = "laplacedot")
stroke.svm

svm_pred = predict(stroke.svm, strokeup,type="response")
confusionMatrix(svm_pred,strokeup$had_stroke,positive="1")
```

# Decision Tree
```{r}
#Build the simplest decision tree
library(C50)
stroke.dt <- C5.0(strokeup[-11], strokeup$had_stroke)

stroke.dt
summary(stroke.dt)
plot(stroke.dt)

#Using model to predict
dt_pred <- predict(stroke.dt,strokeup)
confusionMatrix(as.factor(dt_pred),strokeup$had_stroke,positive = "1")




```

# Stacked Model
```{r}

#Checking to ensure data has been split properly
table(strokeup_norm$had_stroke)
prop.table(table(strokeup_norm$had_stroke))

# Creating Stacked Model
stroke_combined <- data.frame(logit_pred,knn_pred,ann_pred,svm_pred,dt_pred,strokeup$had_stroke)
stroke_combined$had_stroke <- stroke_combined$strokeup.had_stroke
stroke_combined$strokeup.had_stroke <- NULL

#Splitting the data into test and train
index <- createDataPartition(stroke_combined$had_stroke,p=0.7,list=FALSE)
train <- stroke_combined[index,]
test <- stroke_combined[-index,]

#Creating a cost matrix
error_cost <- matrix(c(0, 1, 4, 0), nrow = 2)
error_cost

#Building a new decision tree to make a stacked model
#Apply the cost matrix to the new decision tree

stroke.stacked.model <- C5.0(train[-6],as.factor(train$had_stroke),costs = error_cost)

summary(stroke.stacked.model)

plot(stroke.stacked.model)

stacked_pred <- predict(stroke.stacked.model,test)

confusionMatrix(stacked_pred,as.factor(test$had_stroke),positive = "1")

```

# Non-Up Sampled Decision Tree
```{r}
stroke.dt.noUpsample <- C5.0(stroke[-11],as.factor(stroke$had_stroke))

summary(stroke.dt.noUpsample)

noUpsample_pred <- predict(stroke.dt.noUpsample,stroke)
confusionMatrix(noUpsample_pred,as.factor(stroke$had_stroke))
```


#Conclusion:

Development
In terms of developing our final stacked model., our initial data set had a 95% of samples categorized as not having a stroke, while only 5% of the sample were categorized as having a stroke. Due to the large discrepancy in the dataset, we believed it was best to upsample the data set to get a more balanced number of responses. Before upsampling the dataset, our initial models struggled with low Kappa scores along with unreliable model accuracies. After upsampling, we were able to produce more accurate models. We wanted to highlight our KNN and Decision Tree models using the upsampled data set as the KNN model had an accuracy of 98.95% with a kappa statistic of 0.979, while the Decision Tree model yielded an accuracy of 98.8% with a Kappa score of 0.9759. More importantly, the Decision Tree model using the upsampled data yielded 0 false negatives, which is remarkable given the number of data points in the sample. The stacked model only drew from three of our individual models: Decision Tree, SVM, and Logistic Regression. We were surprised that the KNN model was not included in the stacked model, however, the stacked model produced the highest accuracy and Kappa scores at 98.9% and 0.9781. More importantly, the stacked model produced 0 false negatives, which can prevent doctors from putting patients at risk by predicting a patient will not have a stroke when there is a high risk of the stroke occurring. This model is important as it has the potential to save a lot of lives if implemented correctly.


Means to use Model
In practice, our model could assist physicians in notifying at-risk patients before they have a stroke. It should not be used entirely as a diagnosis, but as an indicator to physicians that a selected patient fits the criteria of someone that has had a stroke in the past. This model could be distributed at a larger scale through major hospital systems where doctors can use the model as an alarm system to notify patients who are at risk of a stroke. This could help make the information-gathering process more efficient for doctors, while also giving them the opportunity to reduce patients’ risk of a stroke by being able to identify risk factors early on.An example of this in play would be a doctor see’s an at-risk patient. The doctor has the ability to act on this immediately and alert the patient to come in for an appointment. This would allow patients to receive tailored recommendations in terms of lifestyle changes such as dietary changes or new medicine prescriptions to further reduce their risk of stroke.


Risks
It is important to note that our data is based on strokes occurring in the past. This could present potential errors as the characteristics of patients pre/post-stroke could be different. We recognize that it would be greatly beneficial to have data for patients before and after strokes occurred in order to filter out characteristics that arise after their stroke. Additionally it would be easier to compare potentially at-risk patients with pre-stroke patients to highlight characteristics that may have lead up to the stroke. Most of our model is not based on data from real patients due to upsampling, which raises a risk of our final stacked models not being representative of real-world data potentially skewing the data and predictions our model makes.Although this model is very accurate at predicting strokes, it doesn't highlight the particular significance of each predictor, making it a black box model. In other words, it doesn't highlight which characteristics specifically are indicative or risks. Therefore if a patient was alerted, the physician wouldn't be able to look at the model and decide which lifestyle characteristics need to be addressed.
